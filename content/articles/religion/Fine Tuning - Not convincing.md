Title: Why the fine tuning argument is not convincing to me
subtitle: (Part 1 of 2)
status: published
date: July 14, 2023
image: jon-flobrant-_r19nfvS3wY-unsplash 1.jpg

The fine-tuning argument is an argument in philosophy and cosmology that suggests the existence of a fine-tuned universe points towards the existence of a intelligent designer or a purpose behind the universe.  It starts with the observation that the fundamental constants and parameters in the universe, such as the strength of gravity, the electromagnetic force, and the mass of elementary particles, have specific values that, if altered even slightly, would render the universe inhospitable to life.  The "even slightly" is a modest way of putting it, to say the least.  

The following are the approximate estimates of the range within which they are thought to allow for life, and what each effect would be made impossible given values outside of the range:

1.  Gravitational constant (G): Around 1 part in $10^{60}$ (formation of stars, galaxies, and planetary systems)
2.  Electromagnetic force strength: Approximately 1 part in $10^{40}$ (the stability of atoms and the ability to form complex structures)
3.  Strong nuclear force coupling constant: Roughly 1 part in $10^{40}$ (binding of atomic nuclei, leading to different chemical elements)
4.  Weak nuclear force coupling constant: About 1 part in $10^{33}$ (rates of nuclear reactions in stars and could prevent the formation of heavier elements)
5.  Cosmological constant (Dark energy density): On the order of 1 part in $10^{120}$ (the delicate balance required for the existence of stable galaxies and cosmic structures)
6.  Ratio of electron to proton mass: Approximately 1 part in $10^{37}$ (formation of atoms and chemical reactions)
7.  Initial entropy of the universe: Extremely low, around 1 part in $10^{10^{123}}$ (evolution of the universe into complex structures necessary for life)

## The argument

As you can see, numbers like 1 part in $10^{120}$ are staggeringly small ranges.  For these precise values to appear randomly is astronomically improbable.  Thus, it is claimed that this is most likely by design.  Apologists typically list three possible (exhaustive) explanations of the fine tuning:

1. random chance
2. physical necessity
3. design

Since (1) is super unlikely, and we have no good reason to suspect (2), then (3) is said to be the best explanation.  


## The first problem is with the "data"

The first problem is not that we have "a set of parameters that are set to specific values within supremely small tolerances". The problem is that we have "current models that have parameters that are only determined empirically (they aren't determined by the theory) that seem to have drastic effects on the theories when the parameters are modified".  How is this different?  

1. It is possible that the fine-tuning of a parameter is an illusion.  We might have a mistake, or an incomplete knowledge of the system, such that the fine tuning doesn't exist.  The expansion rate of the universe is one such case (covered in part of Sean Carroll's debate with William Lane Craig, responding to the Fine Tuning argument.  [Responding to the "Fine Tuning" Argument for God (Sean Carroll)](https://www.youtube.com/watch?v=R97IHcuyWI0&t=363s&pp=ygUYc2VhbiBjYXJyb2xsIGZpbmUgdHVuaW5n "Responding to the "Fine Tuning" Argument for God (Sean Carroll)")), where the naive calculation finds that the probability of that value is 1 part in $10^{60}$ but the complete calculation with general relativity shows that the the probability of that value is equal to 1 -- it *has* to be that value.  Not all parameters are going to be like this, but given our limited understanding, we may not be able to rule that out in many cases.
2. It is possible that the parameters can't be modified independently -- modifying one may necessarily modify another.  In this way, the fine tuning done naively would greatly overestimate the narrowness of the tuning.  

## The second problem is with "life"

Without defining the conditions for the existence of life, one really can't argue that the constants are fine-tuned for life.  Even with the current laws of nature, we can't predict the conditions for life -- we run the risk of bias of seeing all life similar to the carbon-based, material beings we are.  For a short list of imaginative alternatives, we can see [James Fodor list off possible exotic forms of life](https://www.youtube.com/live/7UAHDygN8hk?feature=share&t=9528)
	- silicon based (maybe in another universe with slightly tweaked constants)
	- bound weak-force states even without a periodic table
	- bound strong-force states, making a totally different form of periodic table
	- sulfur-based
	- metal-based
	- crystalline form
	- life on neutron stars
	- life formed from neutrons rather than protons
	- maybe if gravity is stronger, one could have life based on gravity alone
	- photonic form
	- life from dark matter
	- life possible at the quantum scale

As Sean Carroll says, these seem a bit like science fiction, but we are having to imagine changing the fundamental constants of the universe.

For a very detailed covering of this topic see the video from Digital Gnosis: [Bad Apologetics Ep 9 - The Fine Tuning Argument](https://www.youtube.com/watch?v=7UAHDygN8hk&t=4s "Bad Apologetics Ep 9 - The Fine Tuning Argument").

## The third problem is with "God"

Since God could create anything, why would that make it likely that the physical parameters be fine tuned?  God could...

1. make a universe which is hostile for life in every way, and just "miracle-up" life
2. make a universe which is not fine tuned
3. make minds not dependent on physical matter

Given these scenarios, seeing a fine-tuned universe could easily count as evidence *against* God because of all the other ways he could accomplish the same thing.

## What to do when you aren't an expert

One of the issues I face is "what to do when you're not an expert".  How do you figure out what is most likely true?  I have read a lot, and have a background in physics and neuroscience but I'm not a cosmologist.   How does one weigh arguments when seeming experts are at odds with each other?  Personally, I have to ask this question many times when the field is history or political science where I am admittedly out of my depth.  

There are a number of strategies that I use in these cases.

1. Look at the types of counter arguments.  Sean Carroll in his debate with William Lane Craig repeated many times that Craig was either misunderstanding models (for which Carroll is definitely more of an expert) or using the wrong vocabulary altogether.  These kinds of counterarguments are far more devastating than just counter examples.
2. Look for special pleading or cherry picking.  One can often see this where one side is giving general patterns and the other side is giving rare exceptions.
3. Look for cases where one side misrepresents the claims of the other side.  This is a real red-flag.
4. Choose one particular narrow claim and try to verify that.  I do this with political cases, where each side may quote some data on their side as a small part of a larger argument.  I can look up that data and see which side is better representing it.  If one side is distorting or misleading their conclusions from this data, it is more likely they are doing it in other cases.

I plan on writing a follow-up to this post framing the fine-tuning argument probabilistically but this post serves as an introduction to my perspective on this problem.